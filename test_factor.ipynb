{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tools.get_data.get_data_h5 import *\n",
    "from pandasgui import show\n",
    "import talib as ta\n",
    "import datetime\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 获取factor数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factors  as fc\n",
    "def cal_original_factors(symbol, freq = \"minbar\", type = \"future\", source_dir=\"Y:/DataBase_RQ_files/\"):\n",
    "    data = get_data(symbol = symbol, freq = freq, type=type, source_dir=source_dir)\n",
    "    data[\"sma_diff_5\"] = fc.sma_diff(data, 5)\n",
    "    data[\"sma_diff_20000\"] = fc.sma_diff(data, 20000)\n",
    "    data[\"ema_diff_300\"] = fc.ema_diff(data, 300)\n",
    "    data[\"ema_diff_1000\"] = fc.ema_diff(data, 1000)\n",
    "    data[\"sma_of_sma_5_10\"] = fc.sma_of_sma(data, 5, 10)\n",
    "    data[\"ema_of_ema_10_30\"] = fc.ema_of_ema(data, 10, 30)\n",
    "    data[\"sma_diff_sma_5_100\"] = fc.sma_diff_sma(data, 5, 100)\n",
    "    data[\"high_60\"] = fc.high(data, 60)\n",
    "    data[\"low_60\"] = fc.low(data, 60)\n",
    "    data[\"high_60\"] = fc.high(data, 60)\n",
    "    data[\"low_60\"] = fc.low(data, 60)\n",
    "    data[\"wl_60\"] = fc.wl(data, 60)\n",
    "    data[\"wl_60\"] = fc.wl(data, 60)\n",
    "    data[\"macd_dif\"], data[\"macd_dea\"], data[\"macd_hist\"], data[\"macd_signal\"] = fc.MACD(\n",
    "        data, fast=10, slow=60, mid=15)\n",
    "    data[\"slope\"] = fc.slope(data, 60)\n",
    "    data[\"rsi_60\"] = fc.rsi(data, 60)\n",
    "    data[\"sar\"] = fc.sar(data)\n",
    "    data[\"rwr_60\"] = fc.rwr(data, 60)\n",
    "    data[\"rsi_100\"] = fc.rsi(data, 100)\n",
    "    data[\"rwr_100\"] = fc.rwr(data, 100)\n",
    "    data[\"aroon_up\"], data[\"aroon_down\"], data[\"aroon\"] = fc.aroon(data, 60)\n",
    "    data[\"tendstrength\"] = fc.tendstrength(data, 120)\n",
    "    data[\"boll\"] = fc.boll(data, 200)\n",
    "    data[\"don\"] = fc.don(data, 100)\n",
    "    data[\"sf01\"] = fc.sf01(data, 60)\n",
    "    data[\"cor_vol\"] = fc.cor_vol(data, 200)\n",
    "    data[\"cor_oi\"] = fc.cor_oi(data, 1000)    \n",
    "    data.to_parquet(f\".//data//{symbol}_orignal_factors.parquet\")\n",
    "    print(f\"{symbol} done\")\n",
    "# cal_original_factors(\"rb99\")\n",
    "# cal_original_factors(\"ic99\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FactorAnalyzer' from 'e:\\\\Work\\\\5 Research\\\\factor_analysis\\\\FactorAnalyzer.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import FactorAnalyzer as fa\n",
    "reload(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_factors = [\"ic99_orignal_factors.parquet\",\"rb99_orignal_factors.parquet\"]\n",
    "run = True\n",
    "if run:\n",
    "    for symbol in original_factors:\n",
    "        data = pd.read_parquet(\".//data//\"+symbol).dropna()[:100000]\n",
    "        data.set_index(\"datetime\", inplace=True,drop=True)\n",
    "        data = data.drop([\"symbol\",\"trading_date\"],axis=1)\n",
    "        prices = data[\"close\"]\n",
    "        fa_test = fa.FactorRanker(data,prices)\n",
    "        # fa_test.cal_factors_and_rtns(symbol[:4],bins=20,sample_size=2000,save=True)\n",
    "        # fa_test.cal_factors_and_rtns(symbol[:4],bins=20,sample_size=5000,save=True)\n",
    "        # fa_test.cal_factors_and_rtns(symbol[:4],bins=30,sample_size=10000,save=True)\n",
    "        # fa_test.cal_factors_and_rtns(symbol[:4],bins=30,sample_size=20000,save=True)\n",
    "        # fa_test.cal_factors_and_rtns(symbol[:4],bins=30,sample_size=30000,save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\".//data//ic99_2000_20_rank_returns_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rtn_df = data[[exit for exit in data.columns if  \"rtn\" in exit]]\n",
    "\n",
    "# _temp= {}\n",
    "# rolling_days = 20\n",
    "# date = np.unique(data.index.date)\n",
    "# date = np.sort(date)\n",
    "# for day in range(len(date)):\n",
    "#     for  col in rtn_df.columns:\n",
    "#         start = date[day]\n",
    "#         if day+rolling_days <= len(data.index.date):\n",
    "#             end = date[day+rolling_days]\n",
    "#         else:\n",
    "#             end = date[-1]\n",
    "#         print(col)\n",
    "       \n",
    "#         exit_dt :str = col[:-6] + \"exit_dt\"\n",
    "#         print(exit_dt)\n",
    "#         _temp[col]= rtn_df[col][(start <= data[exit_dt].dt.date) & (data[exit_dt].dt.date <= end)]\n",
    "#     _temp_df = pd.DataFrame(_temp)\n",
    "#     print(start,end)\n",
    "#     # if count == 1:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orignal_factors = pd.read_parquet(\".//data//ic99_orignal_factors.parquet\")\n",
    "# show(orignal_factors.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors = pd.read_parquet(\".//data//ic99_2000_20_rank_df.parquet\")\n",
    "# rtn = pd.read_parquet(\".//data//ic99_2000_20_returns_df.parquet\")\n",
    "# show(factors.head(20))\n",
    "# show(rtn.head(20))\n",
    "f_and_r = pd.read_parquet(\".//data//ic99_2000_20_rank_returns_df.parquet\")[30000:50000]\n",
    "factors = f_and_r[[factor for factor in f_and_r.columns if  \"rank\" in factor]]\n",
    "rtn = f_and_r[[rtn for rtn in f_and_r.columns if  \"rtn\" in rtn or \"exit\" in rtn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import FactorAnalyzer as fa\n",
    "reload(fa)\n",
    "rfa = fa.RankFactorAnalyzer(factors,rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfa.cal_rank_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_select,short_select = rfa.factors_select(window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_f,short_f = rfa.factors_select_daily(rolling_days=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(long_f)\n",
    "show(short_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfa.cal_rank_results(long_select,short_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfa.plots(show_dt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "d ={datetime(2021,1,1):s,datetime(2021,1,2):l}\n",
    "df_all = pd.concat(d, names=['date'])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "class FactorAnalyzer:\n",
    "    # ... 其他代码与之前相同\n",
    "    def __init__(self, rank_factors, returns):\n",
    "        self.rank_factors = rank_factors\n",
    "        self.returns = returns\n",
    "        self.data = pd.concat([rank_factors, returns], axis=1)\n",
    "\n",
    "\n",
    "    def analyze_factor_effectiveness(self,ic_value:int = 0.1):\n",
    "        factor_effectiveness = {}\n",
    "\n",
    "        factor_cols=[col for col in self.data.columns if 'rtn' not in col]\n",
    "        rtn_cols = [col for col in self.data.columns if 'rtn' in col]\n",
    "        for factor in factor_cols:\n",
    "            for rtn in rtn_cols:\n",
    "                X = self.data[factor]\n",
    "                X = sm.add_constant(X)\n",
    "                y = self.data[rtn]\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                factor_effectiveness[factor] = {\n",
    "                    'regression_coeff': model.params[factor],\n",
    "                    't_stat': model.tvalues[factor],\n",
    "                    'p_value': model.pvalues[factor]\n",
    "                }\n",
    "\n",
    "        # 计算信息系数（IC）\n",
    "        for factor in factor_cols:\n",
    "            for rtn in rtn_cols:\n",
    "                factor_values = self.data[factor]\n",
    "                future_returns = self.data[rtn]\n",
    "                ic = factor_values.corr(future_returns)\n",
    "                factor_effectiveness[factor]['ic_{}'.format(rtn)] = ic\n",
    "\n",
    "        self.results = pd.DataFrame(factor_effectiveness).T\n",
    "\n",
    "        cond = (self.results >ic_value) + (self.results < -ic_value)\n",
    "        ic_bigger = [(index, column, r.loc[index, column]) \n",
    "                    for column in cond.columns\n",
    "                    for index in cond.index if cond.loc[index, column]]\n",
    "        return self.results,ic_bigger\n",
    "fa_results = FactorAnalyzer(rank_factors, rtn_df)\n",
    "result,ic_bigger = fa_results.analyze_factor_effectiveness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (r>0.07) + (r<-0.1)\n",
    "result = [(index, column, r.loc[index, column]) for column in cond.columns\n",
    "          for index in cond.index if cond.loc[index, column]]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设这是你的DataFrame\n",
    "data = {'A': [1, 4, 2, 8], 'B': [5, 2, 3, 6], 'C': [3, 1, 7, 4]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 使用布尔索引找到所有大于3的数据的位置\n",
    "greater_than_3 = df > 3\n",
    "\n",
    "# 获取大于3的数据的列名、索引和值\n",
    "result = [(index, column, df.loc[index, column])\n",
    "          for column in greater_than_3.columns\n",
    "          for index in greater_than_3.index\n",
    "          if greater_than_3.loc[index, column]]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame()\n",
    "df[\"a\"] ={\"model\":1,\"t\":3123}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_fa.cumsum_plot(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df2 = pd.concat([rank_df, rtn_df], axis=1).dropna()\n",
    "rank_df2.close_rank.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_df = fa_test.cal_returns(rank_df.close)\n",
    "(rtn_df[[\"price\", \"shift_1_rtn\"]]-2/10000 )*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_1[[\"close\",\"shift_1_rtn\"]][2000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df\n",
    "rank_df2 = pd.read_parquet(\".//data//symbol_2000_10_rank_df.parquet\")\n",
    "show(rank_df2[[\"open\", \"high\", \"high_rank\", \"open_rank\"]][:8000], rank_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 因子分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 创建因子rank_df/results_df(耗时长)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.equals(rank_df2[[\"open\", \"high\", \"high_rank\", \"open_rank\"]][:8000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建series\n",
    "factors_1 = factors.set_index(\"datetime\",  drop=True)\n",
    "s = factors_1[\"open\"]\n",
    "type(s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.core.indexes.datetimes.DatetimeIndex is pd.core.indexes.datetimes.DatetimeIndex:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(range(1, 31)) + list(range(30, 201, 5))\n",
    "print(my_list)\n",
    "list(range(31)) + list(range(30, 201, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df2[[\"open\", \"high\", \"high_rank\", \"open_rank\"]][:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload    \n",
    "import factor_analysis as fa\n",
    "reload(fa)\n",
    "data = pd.read_parquet(\".//data//factors.parquet\")\n",
    "data.set_index(\"datetime\", inplace=True, drop=True)\n",
    "factors_cols = []\n",
    "rtn_cols = []\n",
    "for col in data.columns:\n",
    "    if col not in ['datetime', 'trading_date', \"symbol\"]:\n",
    "        if \"rtn\" not in col and \"liqka\" not in col:\n",
    "            factors_cols.append(col)\n",
    "        else:\n",
    "            rtn_cols.append(col)\n",
    "factors = data[factors_cols]\n",
    "rtn = data[rtn_cols]\n",
    "run = 0\n",
    "if run == 1:\n",
    "    fal = fa.FactorAnalysis_ori()\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "    factors, rtn, save=True, sample_size=60000, bins=20)\n",
    "\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=30000, bins=20)\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=20000, bins=15)\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=10000, bins=15)\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=5000, bins=10)\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=2000, bins=10)\n",
    "    rank_df, results_df = fal.cal_rank_results(\n",
    "        factors, rtn, save=True, sample_size=1000, bins=10)\n",
    "    rank_df, results_df = fal.cal_rank_results(factors, rtn,save=True,sample_size=500,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(factors.index) == pd.core.indexes.datetimes.DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接读取rank_df/results_df\n",
    "# print(os.listdir(\".//data//\"))\n",
    "rank_df = pd.read_parquet(\".//data//symbol_2000_10_rank_df.parquet\")\n",
    "results_df = pd.read_parquet(   \".//data//symbol_2000_10_results_df.parquet\")\n",
    "# rank_df = pd.read_parquet(\".//data//symbol_30000_20_rank_df.parquet\")\n",
    "# results_df = pd.read_parquet(\".//data//symbol_30000_20_results_df.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(rank_df.head(500),results_df.head(500))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 因子分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factor_analysis as fa\n",
    "from importlib import reload\n",
    "reload(fa)\n",
    "fal = fa.FactorAnalysis_ori()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df_show = rank_df.head(500)\n",
    "results_df_show = results_df.head(500)\n",
    "select_df = fal.factors_select(rank_df, results_df)\n",
    "show(rank_df_show, results_df_show, select_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rank_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Linda', 'Harry'],\n",
    "        'Age': [18, 19, 20, 19, 18],\n",
    "        'Gender': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'Math Score': [85, 78, 92, 90, 87],\n",
    "        'English Score': [80, 85, 88, 91, 82]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "selected_rows = df.query('Age==18 and `English Score`>5')\n",
    "selected_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factor_analysis as fa\n",
    "from importlib import reload\n",
    "reload(fa)\n",
    "fal = fa.FactorAnalysis_ori()\n",
    "rank_df_e = pd.read_parquet(\".//data//symbol_30000_20_rank_df.parquet\")[:60000]\n",
    "results_df_e = fal.cal_rank_results(factors,rtn,rank_df=rank_df_e)\n",
    "results_df_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# a新增一个元素11\n",
    "a = np.append(a, 11)\n",
    "b =np.array([1]*len(a)) -a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_bar函数会在每一个新的bar到来的时候被调用, 我需要记录每次在long_signal = True 或short_signal = True的时候, 分别记录下bar.close及direction的信息作为入场价格, 另外在触发close_pos > 0或者close < 0 时候的bar.close信息及direction作出出场价格, 然后根据记录的信息计算最近20次交易中的平均收益\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因子分析, 画出最佳因子的累计收益图\n",
    "from importlib import reload\n",
    "import factor_analysis as fa\n",
    "reload(fa)\n",
    "fal = fa.FactorAnalysis_ori()\n",
    "# seletced ={} #选择的因子\n",
    "# show_up = 6\n",
    "# for  i in os.listdir(\".//data//\"):\n",
    "#     if \"30000_20_results\" in i:\n",
    "#         _rank = i.replace(\"_results_df\", \"_rank_df\")\n",
    "#         _rank_df = pd.read_parquet(\".//data//\"+_rank)\n",
    "#         sample_size,bins = i[7:-19].split(\"_\")\n",
    "#         sample_size =int(sample_size)\n",
    "        # bins = int(bins)\n",
    "        #重新计算因子的平均收益,胜率,有效期等信息\n",
    "        # _results_df = fal.cal_rank_results(factors, rtn, rank_df = _rank_df, sample_size=sample_size, bins=bins, save=True)\n",
    "        # _results_df.drop(['long_liqka_mean', 'short_liqka_mean','long_liqka_win_rate', 'short_liqka_win_rate'],axis=1,inplace=True)\n",
    "        \n",
    "        # # _results_df = pd.read_parquet(\".//data//\"+i)\n",
    "        # seletced[i[7:-19]] = fal.factors_select(\n",
    "        #     _results_df, win_rate=0, rtn=-3, count=None, sorted=\"mean_rtn\")\n",
    "        # display(f\"seletced: { i[7:-19]}\" , seletced[i[7:-19]].head())\n",
    "        # fal.cumsum_plot(rank_df = _rank_df, \n",
    "        #                 results_df = _results_df,\n",
    "        #                 n =3,\n",
    "        #                 sorted=\"mean_rtn\")\n",
    "        \n",
    "        # show_up -= 1\n",
    "        # if show_up == 0:\n",
    "            # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 因子有效期分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.read_parquet(\".//data//symbol_30000_20_rank_df.parquet\")\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletced[\"10000_15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"short_liqka_mean\"[:-5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df[['sar_rank', 'rsi_60_rank', 'rwr_60_rank', 'rsi_100_rank','shift_155_rtn', 'shift_160_rtn', 'shift_165_rtn', 'shift_170_rtn']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b43cb0bd93d5abbadd54afed8252f711d4681fe6223ad6b67ffaee289648f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
